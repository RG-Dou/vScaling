# Application / Job
app.class=samzatask.SD.SpikeDetectionApp
job.factory.class=org.apache.samza.job.yarn.ScalableYarnJobFactory
job.name=spike-detection
job.container.single.thread.mode=false
job.container.count=1
job.id=861
job.default.system=kafka
job.debounce.time.ms=5000
#Manual Delay
job.delay.time.us=5000

task.opts=-server -Xms3000M -Xmx3000M

task.checkpoint.factory=org.apache.samza.checkpoint.kafka.KafkaCheckpointManagerFactory
task.checkpoint.system=kafka

# YARN
#yarn.package.path=file://${basedir}/target/${project.artifactId}-${pom.version}-dist.tar.gz
yarn.package.path=hdfs://giraffe:9000/testbed-sd/${project.artifactId}-${pom.version}-dist.tar.gz
yarn.resourcemanager.address=localhost:8032
yarn.container.memory.mb=3000
cluster-manager.container.cpu.cores=1
yarn.am.container.memory.mb=4096
samza.cluster-manager.factory=org.apache.samza.job.yarn.NewYarnResourceManagerFactory
job.container.thread.pool.size=12

#job.controller.factory=org.apache.samza.controller.streamswitch.LatencyGuarantorFactory
job.controller.factory=org.apache.samza.controller.VerticalScalingFactory


# StreamSwitch
# system metrics configs
streamswitch.system.metrics_interval=100
streamswitch.system.warmup_time=60000
#streamswitch.system.metrics_retriever.factory=org.apache.samza.controller.StockMetricsRetrieverFactory
streamswitch.system.metrics_retriever.factory=org.apache.samza.controller.JMXMetricsRetrieverFactory
streamswitch.system.decayfactor=0.95

#metrics retriever configs
yarn.web.address=localhost:8088
topic.number=1
topic.1.name=sensor-logs
#user requirements

# VerticalScaling
verticalscaling.window.metrics=100
verticalscaling.window.regression=4000
verticalscaling.window.pgfault=2000
verticalscaling.block.size=30
verticalscaling.delta.threshold=-1
verticalscaling.cpu.switch=false
verticalscaling.mem.switch=false
verticalscaling.processed_arrival_rate.switch=false
verticalscaling.cpu.algorithm=default
#verticalscaling.cpu.algorithm=elasticutor

task.name.grouper.factory=org.apache.samza.container.grouper.task.GroupByContainerIdsFactory

# Metrics
metrics.reporters=snapshot,jmx
metrics.reporter.snapshot.class=org.apache.samza.metrics.reporter.MetricsSnapshotReporterFactory
metrics.reporter.snapshot.stream=kafka.metrics
metrics.reporter.jmx.class=org.apache.samza.metrics.reporter.JmxReporterFactory
metrics.reporter.snapshot.interval=2

# kafka
systems.kafka.samza.factory=org.apache.samza.system.kafka.KafkaSystemFactory
systems.kafka.consumer.zookeeper.connect=localhost:2181
systems.kafka.producer.bootstrap.servers=localhost:9092
systems.kafka.default.stream.replication.factor=1
job.coordinator.zk.connect=localhost:2181
job.coordinator.zk.session.timeout.ms=400000
task.drop.producer.errors=true

#back-pressure
systems.kafka.samza.fetch.threshold=2560000

## Serializers
serializers.registry.string.class=org.apache.samza.serializers.StringSerdeFactory
serializers.registry.integer.class=org.apache.samza.serializers.IntegerSerdeFactory

job.coordinator.factory=org.apache.samza.zk.FollowerJobCoordinatorFactory
task.execute=bin/run-processor.sh

# Key-value storage
#stores.stock-exchange-sell.factory=org.apache.samza.storage.kv.inmemory.InMemoryKeyValueStorageEngineFactory
stores.device-ID-to-Stream-Map.factory=org.apache.samza.storage.kv.RocksDbKeyValueStorageEngineFactory
stores.device-ID-to-Stream-Map.changelog=kafka.device-ID-to-Stream-Map-changelog
stores.device-ID-to-Stream-Map.key.serde=string
stores.device-ID-to-Stream-Map.msg.serde=string