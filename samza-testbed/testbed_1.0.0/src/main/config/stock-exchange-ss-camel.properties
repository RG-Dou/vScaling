# Application / Job
app.class=samzatask.stock.StockExchangeApp
job.factory.class=org.apache.samza.job.yarn.ScalableYarnJobFactory
job.name=stock-exchange
job.container.single.thread.mode=true
#job.container.thread.pool.size=0
job.container.count=64
job.id=143
job.default.system=kafka
job.debounce.time.ms=5000
#Manual Delay
job.delay.time.ms=5

task.opts=-Xms4096M -Xmx4096M

task.checkpoint.factory=org.apache.samza.checkpoint.kafka.KafkaCheckpointManagerFactory
task.checkpoint.system=kafka

# YARN
#yarn.package.path=file://${basedir}/target/${project.artifactId}-${pom.version}-dist.tar.gz
yarn.package.path=hdfs://camel:9000/testbed/${project.artifactId}-${pom.version}-dist.tar.gz
yarn.resourcemanager.address=camel:8032
yarn.container.memory.mb=2048
yarn.am.container.memory.mb=4096

job.controller.factory=org.apache.samza.controller.streamswitch.LatencyGuarantorFactory

# StreamSwitch
# system metrics configs
streamswitch.system.metrics_interval=100
streamswitch.system.migration_interval=5000
streamswitch.system.warmup_time=40000
streamswitch.system.max_executors=64
streamswitch.system.metrics_retriever.factory=org.apache.samza.controller.streamswitch.JMXMetricsRetrieverFactory
streamswitch.system.alpha=0.5
streamswitch.system.beta=1.0
#metrics retriever configs
yarn.web.address=camel:8088
topic.number=1
topic.1.name=stock_sb
#user requirements
streamswitch.requirement.window=1000
streamswitch.requirement.latency=4000

task.name.grouper.factory=org.apache.samza.container.grouper.task.GroupByContainerIdsFactory

# Metrics
metrics.reporters=snapshot,jmx
metrics.reporter.snapshot.class=org.apache.samza.metrics.reporter.MetricsSnapshotReporterFactory
metrics.reporter.snapshot.stream=kafka.metrics
metrics.reporter.jmx.class=org.apache.samza.metrics.reporter.JmxReporterFactory
metrics.reporter.snapshot.interval=2

# kafka
systems.kafka.consumer.zookeeper.connect=camel:2181
systems.kafka.producer.bootstrap.servers=camel:9092
job.coordinator.zk.connect=camel:2181

## Serializers
serializers.registry.string.class=org.apache.samza.serializers.StringSerdeFactory
serializers.registry.integer.class=org.apache.samza.serializers.IntegerSerdeFactory

job.coordinator.factory=org.apache.samza.zk.FollowerJobCoordinatorFactory
task.execute=bin/run-processor.sh

# Key-value storage
stores.stock-exchange-sell.factory=org.apache.samza.storage.kv.inmemory.InMemoryKeyValueStorageEngineFactory
#stores.stock-exchange-sell.factory=org.apache.samza.storage.kv.RocksDbKeyValueStorageEngineFactory
stores.stock-exchange-sell.changelog=kafka.stock-exchange-sell-changelog
stores.stock-exchange-sell.key.serde=string
stores.stock-exchange-sell.msg.serde=string

stores.stock-exchange-buy.factory=org.apache.samza.storage.kv.inmemory.InMemoryKeyValueStorageEngineFactory
#stores.stock-exchange-buy.factory=org.apache.samza.storage.kv.RocksDbKeyValueStorageEngineFactory
stores.stock-exchange-buy.changelog=kafka.stock-exchange-buy-changelog
stores.stock-exchange-buy.key.serde=string
stores.stock-exchange-buy.msg.serde=string

#systems.kafka.consumer.zookeeper.connect=alligator:2181
#systems.kafka.producer.bootstrap.servers=alligator:9092,buffalo:9092
#job.coordinator.zk.connect=alligator:2181

## Application / Job
#app.class=samzatask.stock.StockExchangeApp
#job.name=stock-exchange
#job.changelog.system=kafka
##task.name.grouper.factory=org.apache.samza.container.grouper.task.SingleContainerGrouperFactory
#processor.id=0
##systems.kafka.default.stream.samza.offset.default=oldest
#job.coordinator.zk.connect=localhost:2181
#job.default.system=kafka
